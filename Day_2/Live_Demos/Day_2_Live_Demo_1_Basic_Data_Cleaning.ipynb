{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_2_Live_Demo_1_Basic_Data_Cleaning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Basic Data Cleaning**"
      ],
      "metadata": {
        "id": "sFcYiVhbweM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, you will learn:\n",
        "\n",
        "* How to identify and remove column variables that only have a single value.\n",
        "* How to identify and consider column variables with very few unique values.\n",
        "* How to identify and remove rows that contain duplicate observations.\n",
        "\n",
        "Adpated from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/)."
      ],
      "metadata": {
        "id": "T-xjYFrCQhmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Messy Dataset\n",
        "\n",
        "\n",
        "Breast cancer dataset classifies breast cancer\n",
        "patient as either a recurrence or no recurrence of cancer. There are 286 examples and nine\n",
        "input variables.\n",
        "\n",
        "You can learn more about the dataset here:\n",
        "* Breast Cancer Dataset ([breast-cancer.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv))\n",
        "* Breast Cancer Dataset Description ([breast-cancer.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "giZ-tn6J7ktc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise: Review the content and description of the Breast cancer dataset by cliking on the links\n",
        "#The !wget command is used to download files from the internet. Format: !wget \"URL\" -O filename.csv. The -O option in the wget command is used to specify the name of the file that you want to save the downloaded content as. In this case, filename.csv is the name of the file where the content from the URL will be saved. Please note that it's not -0 (zero), it's -O (capital o).\n",
        "#download the breast-cancer.csv file and save it as bcancer_data.csv. Then print the first rows of the file.\n",
        "\n",
        "#Your code here"
      ],
      "metadata": {
        "id": "PNbQBqxZaNaz",
        "outputId": "34225c37-20c4-4905-c530-7923336ca4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-22 15:36:42--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24373 (24K) [text/plain]\n",
            "Saving to: ‘bcancer_data.csv’\n",
            "\n",
            "\rbcancer_data.csv      0%[                    ]       0  --.-KB/s               \rbcancer_data.csv    100%[===================>]  23.80K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-22 15:36:42 (14.1 MB/s) - ‘bcancer_data.csv’ saved [24373/24373]\n",
            "\n",
            "'40-49','premeno','15-19','0-2','yes','3','right','left_up','no','recurrence-events'\n",
            "'50-59','ge40','15-19','0-2','no','1','right','central','no','no-recurrence-events'\n",
            "'50-59','ge40','35-39','0-2','no','2','left','left_low','no','recurrence-events'\n",
            "'40-49','premeno','35-39','0-2','yes','3','right','left_low','yes','no-recurrence-events'\n",
            "'40-49','premeno','30-34','3-5','yes','2','left','right_up','no','recurrence-events'\n",
            "'50-59','premeno','25-29','3-5','no','2','right','left_up','yes','no-recurrence-events'\n",
            "'50-59','ge40','40-44','0-2','no','3','left','left_up','no','no-recurrence-events'\n",
            "'40-49','premeno','10-14','0-2','no','2','left','left_up','no','no-recurrence-events'\n",
            "'40-49','premeno','0-4','0-2','no','2','right','right_low','no','no-recurrence-events'\n",
            "'40-49','ge40','40-44','15-17','yes','2','right','left_up','yes','no-recurrence-events'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download messy data file"
      ],
      "metadata": {
        "id": "ibIiSW0g-r4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The messy dataset was modified from Breast Cancer Dataset. It contains an additional column with a unique value. If there is a column that has a constant value across all observations, this is not going to affect the prediction. Such features thus can be removed."
      ],
      "metadata": {
        "id": "eTuuFkqMZ1qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://raw.githubusercontent.com/udel-cbcb/al_ml_workshop/main/data/messy_data.csv\" -O messy_data.csv\n",
        "!head messy_data.csv"
      ],
      "metadata": {
        "id": "4MvsLbWB-hSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d35d37-e77d-4a92-ea5d-daeb52e9da22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-18 02:02:06--  https://raw.githubusercontent.com/udel-cbcb/al_ml_workshop/main/data/messy_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25496 (25K) [text/plain]\n",
            "Saving to: ‘messy_data.csv’\n",
            "\n",
            "\rmessy_data.csv        0%[                    ]       0  --.-KB/s               \rmessy_data.csv      100%[===================>]  24.90K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-18 02:02:06 (22.6 MB/s) - ‘messy_data.csv’ saved [25496/25496]\n",
            "\n",
            "'40-49','premeno','15-19','0-2','yes',4','3','right','left_up','no','recurrence-events'\n",
            "'50-59','ge40','15-19','0-2','no',4','1','right','central','no','no-recurrence-events'\n",
            "'50-59','ge40','35-39','0-2','no',4','2','left','left_low','no','recurrence-events'\n",
            "'40-49','premeno','35-39','0-2','yes',4','3','right','left_low','yes','no-recurrence-events'\n",
            "'40-49','premeno','30-34','3-5','yes',4','2','left','right_up','no','recurrence-events'\n",
            "'50-59','premeno','25-29','3-5','no',4','2','right','left_up','yes','no-recurrence-events'\n",
            "'50-59','ge40','40-44','0-2','no',4','3','left','left_up','no','no-recurrence-events'\n",
            "'40-49','premeno','10-14','0-2','no',4','2','left','left_up','no','no-recurrence-events'\n",
            "'40-49','premeno','0-4','0-2','no',4','2','right','right_low','no','no-recurrence-events'\n",
            "'40-49','ge40','40-44','15-17','yes',4','2','right','left_up','yes','no-recurrence-events'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify Columns That Contain a Single Value\n"
      ],
      "metadata": {
        "id": "sRe1fc_I-MQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the number of unique values for each column using pandas\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "# summarize the number of unique values in each column using nunique()\n",
        "print(\"Shape of messy data: \", df.shape)\n",
        "print(\"Column\\t#Unique values \")\n",
        "print(df.nunique())"
      ],
      "metadata": {
        "id": "Fz3fYIjp_ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bf54bf-b6e2-488d-97ba-62fa6f14029a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of messy data:  (289, 11)\n",
            "Column\t#Unique values \n",
            "0      6\n",
            "1      3\n",
            "2     11\n",
            "3      7\n",
            "4      2\n",
            "5      1\n",
            "6      3\n",
            "7      2\n",
            "8      5\n",
            "9      2\n",
            "10     2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that column index 5 only has a single value and should be removed."
      ],
      "metadata": {
        "id": "OpjQlWtH_qcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Delete columns that contain a single value"
      ],
      "metadata": {
        "id": "1bPtTttf_vga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete columns with a single unique value\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "print(df.shape)\n",
        "# get number of unique values for each column\n",
        "counts = df.nunique()\n",
        "# record columns to delete\n",
        "to_del = [i for i,v in enumerate(counts) if v == 1]\n",
        "print(to_del)\n",
        "# drop useless columns\n",
        "df.drop(to_del, axis=1, inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "738Abx8f_0-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ec97f7-0bf0-4148-a42c-728f40e4fc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289, 11)\n",
            "[5]\n",
            "(289, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify columns that have very few values"
      ],
      "metadata": {
        "id": "i5bW7pFsAI3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "# summarize the number of unique values in each column\n",
        "print(\"Column, Count, <1%\")\n",
        "for i, v in enumerate(df.nunique()):\n",
        "  percentage = float(v) / df.shape[0] * 100\n",
        "  if percentage < 1:\n",
        "    print('%d, %d, %.1f%%' % (i, v, percentage))"
      ],
      "metadata": {
        "id": "qW3BwXIOFbfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccda87e-0949-4e9a-8d35-3956a276a093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column, Count, <1%\n",
            "4, 2, 0.7%\n",
            "5, 1, 0.3%\n",
            "7, 2, 0.7%\n",
            "9, 2, 0.7%\n",
            "10, 2, 0.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Drop columns with unique values less than 1 percent of rows"
      ],
      "metadata": {
        "id": "vnjw39eIF2kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete columns where number of unique values is less than 1% of the rows\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "print(df.shape)\n",
        "# get number of unique values for each column\n",
        "counts = df.nunique()\n",
        "# record columns to delete\n",
        "to_del = [i for i,v in enumerate(counts) if (float(v)/df.shape[0] * 100) < 1]\n",
        "print(\"Columns to delete: \", to_del)\n",
        "# drop useless columns\n",
        "df.drop(to_del, axis=1, inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "KiPY_mBqGGeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018d5517-1cff-4baf-9d95-89cac42d00d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289, 11)\n",
            "Columns to delete:  [4, 5, 7, 9, 10]\n",
            "(289, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify rows that contain duplicate data"
      ],
      "metadata": {
        "id": "fOPZfL-JPe7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# locate rows of duplicate data\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "# calculate duplicates\n",
        "dups = df.duplicated()\n",
        "# report if there are any duplicates\n",
        "print(\"Any duplicates? \", dups.any())\n",
        "# list all duplicate rows\n",
        "print(\"Duplicated rows:\")\n",
        "print(df[dups])"
      ],
      "metadata": {
        "id": "WFrSFoZRPnpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b1d448-55f9-4454-836f-ca59051bb5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any duplicates?  True\n",
            "Duplicated rows:\n",
            "          0          1        2      3      4   5    6        7           8   \\\n",
            "17   '60-69'     'ge40'  '15-19'  '0-2'   'no'  4'  '2'  'right'   'left_up'   \n",
            "27   '40-49'  'premeno'  '10-14'  '0-2'   'no'  4'  '1'  'right'   'left_up'   \n",
            "44   '30-39'  'premeno'  '15-19'  '0-2'   'no'  4'  '1'   'left'  'left_low'   \n",
            "65   '50-59'     'ge40'  '15-19'  '0-2'   'no'  4'  '1'  'right'   'central'   \n",
            "117  '60-69'     'ge40'  '10-14'  '0-2'   'no'  4'  '1'   'left'   'left_up'   \n",
            "178  '40-49'  'premeno'  '25-29'  '0-2'   'no'  4'  '2'  'right'  'left_low'   \n",
            "190  '50-59'  'premeno'  '25-29'  '0-2'   'no'  4'  '2'   'left'  'right_up'   \n",
            "214  '40-49'  'premeno'  '20-24'  '0-2'   'no'  4'  '2'  'right'   'left_up'   \n",
            "217  '50-59'  'premeno'  '25-29'  '0-2'   'no'  4'  '2'   'left'  'left_low'   \n",
            "221  '50-59'     'ge40'  '20-24'  '0-2'   'no'  4'  '3'   'left'   'left_up'   \n",
            "237  '30-39'     'lt40'  '15-19'  '0-2'   'no'  4'  '3'  'right'   'left_up'   \n",
            "240  '50-59'     'ge40'  '40-44'  '6-8'  'yes'  4'  '3'   'left'  'left_low'   \n",
            "246  '60-69'     'ge40'  '15-19'  '0-2'   'no'  4'  '2'   'left'  'left_low'   \n",
            "268  '30-39'  'premeno'  '35-39'  '0-2'   'no'  4'  '3'   'left'  'left_low'   \n",
            "270  '60-69'     'ge40'  '20-24'  '0-2'   'no'  4'  '1'   'left'  'left_low'   \n",
            "287  '40-49'  'premeno'  '20-24'  '0-2'   'no'  4'  '2'  'right'  'right_up'   \n",
            "288  '50-59'     'ge40'  '40-44'  '0-2'   'no'  4'  '2'   'left'  'left_low'   \n",
            "\n",
            "        9                       10  \n",
            "17    'no'  'no-recurrence-events'  \n",
            "27    'no'  'no-recurrence-events'  \n",
            "44    'no'  'no-recurrence-events'  \n",
            "65    'no'  'no-recurrence-events'  \n",
            "117   'no'  'no-recurrence-events'  \n",
            "178   'no'     'recurrence-events'  \n",
            "190   'no'     'recurrence-events'  \n",
            "214   'no'  'no-recurrence-events'  \n",
            "217   'no'  'no-recurrence-events'  \n",
            "221   'no'  'no-recurrence-events'  \n",
            "237   'no'  'no-recurrence-events'  \n",
            "240  'yes'     'recurrence-events'  \n",
            "246   'no'  'no-recurrence-events'  \n",
            "268   'no'     'recurrence-events'  \n",
            "270   'no'  'no-recurrence-events'  \n",
            "287   'no'  'no-recurrence-events'  \n",
            "288   'no'  'no-recurrence-events'  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Delete rows that contain duplicate data"
      ],
      "metadata": {
        "id": "noMvFc6AP-53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete rows of duplicate data from the dataset\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv('messy_data.csv', header=None)\n",
        "print(df.shape)\n",
        "# delete duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "G4VBQ_dIQEes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577eb0da-6195-4e3a-849f-df8a37e8e7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289, 11)\n",
            "(272, 11)\n"
          ]
        }
      ]
    }
  ]
}