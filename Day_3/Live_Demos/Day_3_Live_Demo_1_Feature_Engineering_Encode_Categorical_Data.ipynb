{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_3_Live_Demo_1_Feature_Engineering_Encode_Categorical_Data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOaH5qwh0kzkMo4FSilUQ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Encode Categorical Data**\n","\n"],"metadata":{"id":"mfyjWBlmvoQE"}},{"cell_type":"markdown","source":["Machine learning models require all input and output variables to be numeric. This means\n","that if your data contains categorical data, you must encode it to numbers before you can fit\n","and evaluate a model. The two most popular techniques are an Ordinal encoding and a One\n","Hot encoding.\n","\n","In this tutorial, you will learn:\n","\n","* Encoding is a required pre-processing step when working with categorical data for machine\n","learning algorithms.\n","* How to use ordinal encoding for categorical variables that have a natural rank ordering.\n","* How to use one hot encoding for categorical variables that do not have a natural rank\n","ordering.\n","\n","Credit: Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/)."],"metadata":{"id":"PzI4Y70AXgqb"}},{"cell_type":"markdown","source":["##Nominal and Ordinal Variables\n","\n","* **Nominal Variable**. Variable comprises a finite set of discrete values with no rank-order\n","relationship between values.\n","* **Ordinal Variable**. Variable comprises a finite set of discrete values with a ranked\n","ordering between values.\n","\n","Some algorithms can work with categorical data directly. For example, a decision tree can\n","be learned directly from categorical data with no data transform required (this depends on\n","the specific implementation). Many machine learning algorithms cannot operate on label data\n","directly. They require all input variables and output variables to be numeric. In general, this is\n","mostly a constraint of the effcient implementation of machine learning algorithms rather than\n","hard limitations on the algorithms themselves.\n","\n","Some implementations of machine learning algorithms require all data to be numerical. This means that categorical data must be converted\n","to a numerical form. If the categorical variable is an output variable, you may also want to\n","convert predictions by the model back into a categorical form in order to present them or use\n","them in some application."],"metadata":{"id":"mDLmE8s1Ugy8"}},{"cell_type":"markdown","source":["##Encoding Categorical Data\n","\n","There are three common approaches for converting ordinal and categorical variables to numerical\n","values. They are:\n","* Ordinal Encoding\n","* One Hot Encoding\n","* Dummy Variable Encoding"],"metadata":{"id":"ZowEabAnU7ZS"}},{"cell_type":"markdown","source":["###Ordinal Encoding\n","In ordinal encoding, each unique category value is assigned an integer value. An integer ordinal encoding is a natural encoding for ordinal variables. For categorical\n","variables, it imposes an ordinal relationship where no such relationship may exist. This can\n","cause problems and a one hot encoding may be used instead."],"metadata":{"id":"TmK0Xa7kVS7J"}},{"cell_type":"code","source":["# example of a ordinal encoding\n","from numpy import asarray\n","from sklearn.preprocessing import OrdinalEncoder\n","# define data\n","data = asarray([['red'], ['green'], ['blue']])\n","print(data)\n","# define ordinal encoding\n","encoder = OrdinalEncoder()\n","# transform data\n","result = encoder.fit_transform(data)\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xyZsQU5VhfF","executionInfo":{"status":"ok","timestamp":1651761452604,"user_tz":240,"elapsed":152,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"e36939ca-6c84-4224-ce6f-e70eb8c7c31f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[['red']\n"," ['green']\n"," ['blue']]\n","[[2.]\n"," [1.]\n"," [0.]]\n"]}]},{"cell_type":"markdown","source":["We\n","can see that the numbers are assigned to the labels as we expected.\n","\n","This **OrdinalEncoder** class is intended for input variables that are organized into rows and\n","columns, e.g. a matrix. If a categorical target variable needs to be encoded for a classification\n","problem, then the **LabelEncoder** class can be used. It does the same\n","thing as the **OrdinalEncoder**, although it expects a one-dimensional input for the single target\n","variable."],"metadata":{"id":"_vCGhBZRVlvL"}},{"cell_type":"markdown","source":["###One Hot Encoding\n","For categorical variables where no ordinal relationship exists, the integer encoding may not be\n","enough or even misleading to the model. Forcing an ordinal relationship via an ordinal encoding\n","and allowing the model to assume a natural ordering between categories may result in poor\n","performance or unexpected results (predictions halfway between categories). In this case, a one\n","hot encoding can be applied to the ordinal representation. This is where the integer encoded\n","variable is removed and one new binary variable is added for each unique integer value in the\n","variable."],"metadata":{"id":"gGRRlv1kV_WE"}},{"cell_type":"code","source":["# example of a one hot encoding\n","from numpy import asarray\n","from sklearn.preprocessing import OneHotEncoder\n","# define data\n","data = asarray([['red'], ['green'], ['blue']])\n","print(data)\n","# define one hot encoding\n","encoder = OneHotEncoder(sparse=False)\n","# transform data\n","onehot = encoder.fit_transform(data)\n","print(onehot)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjIgiHuMWUrm","executionInfo":{"status":"ok","timestamp":1646924511574,"user_tz":300,"elapsed":190,"user":{"displayName":"Chuming Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17839229876463490728"}},"outputId":"d3daee5a-de4d-41d1-b9ab-e25e6e0100dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['red']\n"," ['green']\n"," ['blue']]\n","[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]]\n"]}]},{"cell_type":"markdown","source":["We can see the one hot encoding\n","matching our expectation of 3 binary variables in the order blue, green and red."],"metadata":{"id":"14cOFbh3Wd98"}},{"cell_type":"markdown","source":["###Dummy Variable Encoding\n","The one hot encoding creates one binary variable for each category. The problem is that this\n","representation includes redundancy. For example, if we know that [1, 0, 0] represents blue and\n","[0, 1, 0] represents green we don't need another binary variable to represent red, instead we\n","could use 0 values alone, e.g. [0, 0]. This is called a dummy variable encoding, and always\n","represents C categories with C - 1 binary variables."],"metadata":{"id":"hSr3W82IWouT"}},{"cell_type":"markdown","source":["We can use the OneHotEncoder class to implement a dummy encoding as well as a one hot\n","encoding. The drop argument can be set to indicate which category will become the one that is\n","assigned all zero values, called the baseline. We can set this to `firrst' so that the first category is\n","used. When the labels are sorted alphabetically, the blue label will be the first and will become\n","the baseline."],"metadata":{"id":"9KrnoPcFXRjY"}},{"cell_type":"code","source":["# example of a dummy variable encoding\n","from numpy import asarray\n","from sklearn.preprocessing import OneHotEncoder\n","# define data\n","data = asarray([['red'], ['green'], ['blue']])\n","print(data)\n","# define one hot encoding\n","encoder = OneHotEncoder(drop='first', sparse=False)\n","# transform data\n","onehot = encoder.fit_transform(data)\n","print(onehot)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pq_KDVmeXShw","executionInfo":{"status":"ok","timestamp":1646924748343,"user_tz":300,"elapsed":167,"user":{"displayName":"Chuming Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17839229876463490728"}},"outputId":"9bbbe6f1-14bc-4d9a-bff3-d48a4ed13ade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['red']\n"," ['green']\n"," ['blue']]\n","[[0. 1.]\n"," [1. 0.]\n"," [0. 0.]]\n"]}]},{"cell_type":"markdown","source":["##Breast Cancer Categorical Dataset\n","Breast cancer dataset classifies breast cancer\n","patient data as either a recurrence or no recurrence of cancer. There are 286 examples and nine\n","input variables. It is a binary classification problem. A naive model can achieve an accuracy\n","of 70 percent on this dataset. A good score is about 76 percent. \n","\n","You can learn more about the dataset here:\n","* Breast Cancer Dataset ([breast-cancer.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv))\n","* Breast Cancer Dataset Description ([breast-cancer.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names))"],"metadata":{"id":"jMA441NTYalQ"}},{"cell_type":"markdown","source":["###Download Breast Cancer data files"],"metadata":{"id":"LgNi_b2VYgUW"}},{"cell_type":"code","source":["!wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\" -O breast-cancer.csv\n","!wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names\" -O breast-cancer.names\n","!head breast-cancer.csv"],"metadata":{"id":"K31efwEBYisf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651761923968,"user_tz":240,"elapsed":660,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"9a7beb14-116f-458a-f927-d5615832cfca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-05 14:45:23--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 24373 (24K) [text/plain]\n","Saving to: ‘breast-cancer.csv’\n","\n","\rbreast-cancer.csv     0%[                    ]       0  --.-KB/s               \rbreast-cancer.csv   100%[===================>]  23.80K  --.-KB/s    in 0.004s  \n","\n","2022-05-05 14:45:23 (5.48 MB/s) - ‘breast-cancer.csv’ saved [24373/24373]\n","\n","--2022-05-05 14:45:23--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3162 (3.1K) [text/plain]\n","Saving to: ‘breast-cancer.names’\n","\n","breast-cancer.names 100%[===================>]   3.09K  --.-KB/s    in 0s      \n","\n","2022-05-05 14:45:23 (43.5 MB/s) - ‘breast-cancer.names’ saved [3162/3162]\n","\n","'40-49','premeno','15-19','0-2','yes','3','right','left_up','no','recurrence-events'\n","'50-59','ge40','15-19','0-2','no','1','right','central','no','no-recurrence-events'\n","'50-59','ge40','35-39','0-2','no','2','left','left_low','no','recurrence-events'\n","'40-49','premeno','35-39','0-2','yes','3','right','left_low','yes','no-recurrence-events'\n","'40-49','premeno','30-34','3-5','yes','2','left','right_up','no','recurrence-events'\n","'50-59','premeno','25-29','3-5','no','2','right','left_up','yes','no-recurrence-events'\n","'50-59','ge40','40-44','0-2','no','3','left','left_up','no','no-recurrence-events'\n","'40-49','premeno','10-14','0-2','no','2','left','left_up','no','no-recurrence-events'\n","'40-49','premeno','0-4','0-2','no','2','right','right_low','no','no-recurrence-events'\n","'40-49','ge40','40-44','15-17','yes','2','right','left_up','yes','no-recurrence-events'\n"]}]},{"cell_type":"code","source":["# load and summarize the dataset\n","from pandas import read_csv\n","# load the dataset\n","dataset = read_csv('breast-cancer.csv', header=None)\n","# retrieve the array of data\n","data = dataset.values\n","# separate into input and output columns\n","X = data[:, :-1].astype(str)\n","y = data[:, -1].astype(str)\n","# summarize\n","print('Input', X.shape)\n","print('Output', y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsaRq0cpYmXE","executionInfo":{"status":"ok","timestamp":1651761930041,"user_tz":240,"elapsed":340,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"3c46c8a1-1827-4356-dfe2-a205380acd2a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (286, 9)\n","Output (286,)\n"]}]},{"cell_type":"markdown","source":["We\n","can see that we have 286 examples and nine input variables.\n","\n"],"metadata":{"id":"SHroPZtkYrta"}},{"cell_type":"markdown","source":["###OrdinalEncoder Transform\n","An ordinal encoding involves mapping each unique label to an integer value. This type of\n","encoding is really only appropriate if there is a known relationship between the categories. This\n","relationship does exist for some of the variables in our dataset, and ideally, this should be\n","harnessed when preparing the data. In this case, we will ignore any possible existing ordinal\n","relationship and assume all variables are categorical. It can still be helpful to use an ordinal\n","encoding, at least as a point of reference with other encoding schemes.\n","We can use the OrdinalEncoder from scikit-learn to encode each variable to integers."],"metadata":{"id":"Dn1kp-88ZiTb"}},{"cell_type":"code","source":["# ordinal encode the breast cancer dataset\n","from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","# load the dataset\n","dataset = read_csv('breast-cancer.csv', header=None)\n","# retrieve the array of data\n","data = dataset.values\n","# separate into input and output columns\n","X = data[:, :-1].astype(str)\n","y = data[:, -1].astype(str)\n","# ordinal encode input variables\n","ordinal_encoder = OrdinalEncoder()\n","X = ordinal_encoder.fit_transform(X)\n","# ordinal encode target variable\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","# summarize the transformed data\n","print('Input', X.shape)\n","print(X[:5, :])\n","print('Output', y.shape)\n","print(y[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tT9bkIhY79m","executionInfo":{"status":"ok","timestamp":1651762080527,"user_tz":240,"elapsed":212,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"66e4ebf6-b720-4251-a0c2-b751dbd7a86c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (286, 9)\n","[[2. 2. 2. 0. 1. 2. 1. 2. 0.]\n"," [3. 0. 2. 0. 0. 0. 1. 0. 0.]\n"," [3. 0. 6. 0. 0. 1. 0. 1. 0.]\n"," [2. 2. 6. 0. 1. 2. 1. 1. 1.]\n"," [2. 2. 5. 4. 1. 1. 0. 4. 0.]]\n","Output (286,)\n","[1 0 1 0 1]\n"]}]},{"cell_type":"markdown","source":["We would expect the number of rows, and in this case, the number of columns, to be unchanged,\n","except all string values are now integer values. As expected, in this case, we can see that the\n","number of variables is unchanged, but all values are now ordinal encoded integers."],"metadata":{"id":"J9D0Oh56ZEIk"}},{"cell_type":"markdown","source":["Next, let's evaluate machine learning on this dataset with this encoding. The best practice\n","when encoding variables is to fit the encoding on the training dataset, then apply it to the train\n","and test datasets. We will first split the dataset, then prepare the encoding on the training set,\n","and apply it to the test set."],"metadata":{"id":"i4aA5VKVZIM0"}},{"cell_type":"code","source":["# evaluate logistic regression on the breast cancer dataset with an ordinal encoding\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.metrics import accuracy_score\n","# load the dataset\n","dataset = read_csv('breast-cancer.csv', header=None)\n","# retrieve the array of data\n","data = dataset.values\n","# separate into input and output columns\n","X = data[:, :-1].astype(str)\n","y = data[:, -1].astype(str)\n","# split the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n","# ordinal encode input variables\n","ordinal_encoder = OrdinalEncoder()\n","ordinal_encoder.fit(X_train)\n","X_train = ordinal_encoder.transform(X_train)\n","X_test = ordinal_encoder.transform(X_test)\n","# ordinal encode target variable\n","label_encoder = LabelEncoder()\n","label_encoder.fit(y_train)\n","y_train = label_encoder.transform(y_train)\n","y_test = label_encoder.transform(y_test)\n","# define the model\n","model = LogisticRegression()\n","# fit on the training set\n","model.fit(X_train, y_train)\n","# predict on test set\n","yhat = model.predict(X_test)\n","# evaluate predictions\n","accuracy = accuracy_score(y_test, yhat)\n","print('Accuracy: %.2f' % (accuracy*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ajy4tca-ZLhL","executionInfo":{"status":"ok","timestamp":1651762189472,"user_tz":240,"elapsed":324,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"42ac89e3-4fa0-4856-932c-9d0f0e6be9f4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 75.79\n"]}]},{"cell_type":"markdown","source":["In this case, the model achieved a classi cation accuracy of about 75.79 percent, which is a\n","reasonable score."],"metadata":{"id":"jvCWz1FVZTKY"}},{"cell_type":"markdown","source":["###OneHotEncoder Transform\n","A one hot encoding is appropriate for categorical data where no relationship exists between\n","categories. The scikit-learn library provides the OneHotEncoder class to automatically one hot\n","encode one or more variables. By default the OneHotEncoder will output data with a sparse\n","representation, which is efficient given that most values are 0 in the encoded representation.\n","We will disable this feature by setting the sparse argument to False so that we can review the\n","effect of the encoding. Once defined, we can call the fit transform() function and pass it to\n","our dataset to create a quantile transformed version of our dataset."],"metadata":{"id":"iOIGeNTZZav_"}},{"cell_type":"code","source":["# one-hot encode the breast cancer dataset\n","from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# load the dataset\n","dataset = read_csv('breast-cancer.csv', header=None)\n","# retrieve the array of data\n","data = dataset.values\n","# separate into input and output columns\n","X = data[:, :-1].astype(str)\n","y = data[:, -1].astype(str)\n","# one hot encode input variables\n","onehot_encoder = OneHotEncoder(sparse=False)\n","X = onehot_encoder.fit_transform(X)\n","# ordinal encode target variable\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","# summarize the transformed data\n","print('Input', X.shape)\n","print(X[:5, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2yHzAZ2HZnmS","executionInfo":{"status":"ok","timestamp":1651762276893,"user_tz":240,"elapsed":140,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"c81085cb-a4b8-4727-b4af-2ba495556375"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (286, 43)\n","[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n","  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n","  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n","  0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n","  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]]\n"]}]},{"cell_type":"markdown","source":["We would expect the number of rows to remain the same, but the number of columns to\n","dramatically increase. As expected, in this case, we can see that the number of variables has\n","leaped up from 9 to 43 and all values are now binary values 0 or 1."],"metadata":{"id":"iGk-WswwZ0uQ"}},{"cell_type":"markdown","source":["Next, let's evaluate machine learning on this dataset with this encoding as we did in the\n","previous section. The encoding is fit on the training set then applied to both train and test sets\n","as before."],"metadata":{"id":"K7iVK_KMaAvE"}},{"cell_type":"code","source":["# evaluate logistic regression on the breast cancer dataset with a one-hot encoding\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score\n","# load the dataset\n","dataset = read_csv('breast-cancer.csv', header=None)\n","# retrieve the array of data\n","data = dataset.values\n","# separate into input and output columns\n","X = data[:, :-1].astype(str)\n","y = data[:, -1].astype(str)\n","# split the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n","# one-hot encode input variables\n","onehot_encoder = OneHotEncoder()\n","onehot_encoder.fit(X_train)\n","X_train = onehot_encoder.transform(X_train)\n","X_test = onehot_encoder.transform(X_test)\n","# ordinal encode target variable\n","label_encoder = LabelEncoder()\n","label_encoder.fit(y_train)\n","y_train = label_encoder.transform(y_train)\n","y_test = label_encoder.transform(y_test)\n","# define the model\n","model = LogisticRegression()\n","# fit on the training set\n","model.fit(X_train, y_train)\n","# predict on test set\n","yhat = model.predict(X_test)\n","# evaluate predictions\n","accuracy = accuracy_score(y_test, yhat)\n","print('Accuracy: %.2f' % (accuracy*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJp4KyfXaEf1","executionInfo":{"status":"ok","timestamp":1651762328454,"user_tz":240,"elapsed":134,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"1d486751-fa3f-4819-e80a-237211c0bb21"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 70.53\n"]}]},{"cell_type":"markdown","source":["In this case, the model achieved a classifcation accuracy of about 70.53 percent, which is\n","worse than the ordinal encoding in the previous section."],"metadata":{"id":"raB8Y7YRaLMN"}}]}