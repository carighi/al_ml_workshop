{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKAkzuPVhZBECLxTamVSZc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carighi/al_ml_workshop/blob/main/Useful_tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Goal\n",
        "The goal of this notebook is to collect libraries and functions that you may need in your final project"
      ],
      "metadata": {
        "id": "DJWoD8iMY5Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Info about libraries\n",
        "\n",
        "Use `import` to import a package or a function:\n",
        "\n",
        "*  Import a library and assign an alias:  `import pandas as pd` #This imports the pandas library and gives it the alias pd\n",
        "\n",
        "*  Import a class within a library, so it can be used without needed to prefix it with package name: `from sklearn.preprocessing import OneHotEncoder` #Importing OneHotEncoder directly allows you to use it without needing to prefix it with sklearn.preprocessing.\n"
      ],
      "metadata": {
        "id": "spUrQhcUZOgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Libraries for final project\n",
        "These imports set up the necessary tools for data manipulation, visualization, model training, and evaluation.\n",
        "\n",
        "`from pandas import read_csv` Imports the read_csv function from the pandas library, which is used to read data from a CSV file into a DataFrame.\n",
        "\n",
        "`from numpy import asarray` Imports the asarray function from the numpy library, which is used to convert input data into an array.\n",
        "\n",
        "`from matplotlib import pyplot as plt`  Imports the pyplot module from the matplotlib library, which is used for creating plots and visualizations.\n",
        "\n",
        "`from sklearn.model_selection import train_test_split` Imports the train_test_split function from scikit-learn, which is used to split data into training and testing sets.\n",
        "\n",
        "`from sklearn.metrics import classification_report` Imports functions for evaluating the performance of a classification model\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix` Imports functions for evaluating the performance of a classification model\n",
        "\n",
        "`from sklearn.metrics import accuracy_score` Imports functions for evaluating the performance of a classification model\n",
        "\n",
        "`from sklearn.neighbors import KNeighborsClassifier` Imports the KNeighborsClassifier class, which is used to create a k-nearest neighbors classifier.\n",
        "\n",
        "`from sklearn.svm import SVC` Imports the SVC class, which is used to create a support vector machine classifier."
      ],
      "metadata": {
        "id": "xIWH2BHecV6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Functions to upload files\n",
        "###Upload csv file using pandas\n",
        "\n",
        "Example 1\n",
        "```\n",
        "from pandas import read_csv\n",
        "#create variable for assigning file location\n",
        "file_location = \"filepath and name\"\n",
        "\n",
        "#if you have to add headers, use name= parameter.\n",
        "colnames = ['name1','name2', ....,'name3']\n",
        "read_csv (file_location, names=colnames)\n",
        "```\n",
        "###Example 2\n",
        "\n",
        "\n",
        "```\n",
        "from pandas import read_csv\n",
        "!wget -O filename.csv \"url\"\n",
        "#Then you need to read with pandas\n",
        "dataset=read_csv('filename.csv')\n",
        "#if your dataset has no headers then you shoud add the parameter header=none when you read the file\n",
        "dataset=read_csv('filename.csv', header=None)\n",
        "# or add the header with parameter name=['name1','name2', ....,'name3']\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zsdZxhjkej0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating training and test datasets\n",
        "\n",
        "1. First we need to split features and labels (target) into x and y datasets.\n",
        "\n",
        "This part uses train_test_split (need to import if you don't have it)\n",
        "Once you have your dataset values in an array\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#let's say you assign your dataset preprocessed values to array\n",
        "\n",
        "array=<dataset values>\n",
        "\n",
        "#you need to define the columns that are the features to x and those that are the labels to y\n",
        "\n",
        "x= array [<range for feature data>]\n",
        "\n",
        "y= array [<add range for labels>]\n",
        "```\n",
        "\n",
        "2. Now that we have the features and labels (target), then you can split into training and test set\n",
        "\n",
        "`X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=<test size>, random_state=<any number>)`\n"
      ],
      "metadata": {
        "id": "wff188-DmN8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run models\n",
        "SVM and K-near neighbors are from sklearn.\n",
        "The skeleton is similar but parameters are different\n",
        "\n",
        "**For SVM**\n",
        "\n",
        "Set C and Kernel parameters\n",
        "```\n",
        "from sklearn.svm import SVC\n",
        "#remember 'random_state' parameter is used for reproducibility of the results each time we run this cell\n",
        "svm = SVC(kernel=\"linear\", C=<value>, random_state=<number>)\n",
        "svm.fit(X_train, y_train)\n",
        "#score returns the mean accuracy\n",
        "predictions = svm.predict (X_test)\n",
        "svm.score(X_test, y_test)\n",
        "```\n",
        "\n",
        "**For K-Near neighbors**\n",
        "\n",
        "Set up n_neighbors (k)\n",
        "```\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier(n_neighbors=<number>)\n",
        "KNN.fit(X_train, y_train)\n",
        "predictions = KNN.predict(X_test)\n",
        "KNN.score(X_test, y_test)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qOsq_KDA4p57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance metrics\n",
        "\n",
        "For this part, the sklearn.metrics classes are used\n",
        "\n",
        "To get the confusion matrix\n",
        "\n",
        "\n",
        "```\n",
        "print(confusion_matrix(<test labels>, <prediction>))\n",
        "```\n",
        "\n",
        "To get metrics summary (precision, recall, F-score), use classification_report\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "print(classification_report(<testlabels>, <prediction>))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PMJcvGIP6QIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##General functions to manipulate data\n",
        "\n",
        "\n",
        "\n",
        ".head(): Returns the first n rows of a DataFrame. By default, it returns the first 5 rows.\n",
        "\n",
        ".shape(): Returns a tuple representing the dimensionality of the DataFrame (number of rows, number of columns).\n",
        "\n",
        ".describe(): Generates descriptive statistics of the DataFrame, such as count, mean, std, min, and max for numerical columns.\n",
        "\n",
        ".dtypes(): Returns the data types of each column in the DataFrame.\n",
        "\n",
        ".groupby(): Groups the DataFrame using a mapper or by a series of columns. It is often used for aggregation.\n",
        "\n",
        ".duplicated(): Returns a Boolean Series indicating whether each row is a duplicate or not.\n",
        "\n",
        ".dropna(): Removes missing values from the DataFrame. By default, it drops any row with at least one missing value.\n",
        "\n"
      ],
      "metadata": {
        "id": "S_1Gs3Q4_hLF"
      }
    }
  ]
}